version: '3.8'

services:
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    depends_on:
      - kafka0
      #      - kafka1
      - schemaregistry0
      #      - schemaregistry1
      - kafka-connect0
      - postgres
      - redis
    #      - redis-sink-connector
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka0:29092
      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schemaregistry0:8085
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect0:8083
      #      KAFKA_CLUSTERS_1_NAME: secondLocal
      #      KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: kafka1:29092
      #      KAFKA_CLUSTERS_1_METRICS_PORT: 9998
      #      KAFKA_CLUSTERS_1_SCHEMAREGISTRY: http://schemaregistry1:8085
      DYNAMIC_CONFIG_ENABLED: 'true'

  kafka0:
    image: confluentinc/cp-kafka:7.2.1
    hostname: kafka0
    container_name: kafka0
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9997:9997"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka0:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9997
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka0:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka0:29092,CONTROLLER://kafka0:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - ./scripts/update_run.sh:/tmp/update_run.sh
    command: >
      bash -c 'if [ ! -f /tmp/update_run.sh ]; then 
                 echo "ERROR: Did you forget the update_run.sh file?" && exit 1; 
               else 
                 chmod +x /tmp/update_run.sh && /tmp/update_run.sh && /etc/confluent/docker/run; 
               fi'

  #  kafka1:
  #    image: confluentinc/cp-kafka:7.2.1
  #    hostname: kafka1
  #    container_name: kafka1
  #    ports:
  #      - "9093:9092"
  #      - "9998:9998"
  #    environment:
  #      KAFKA_BROKER_ID: 1
  #      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
  #      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092'
  #      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #      KAFKA_JMX_PORT: 9998
  #      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9998
  #      KAFKA_PROCESS_ROLES: 'broker,controller'
  #      KAFKA_NODE_ID: 1
  #      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093'
  #      KAFKA_LISTENERS: 'PLAINTEXT://kafka1:29092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:9092'
  #      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
  #      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
  #      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
  #    volumes:
  #      - ./scripts/update_run.sh:/tmp/update_run.sh
  #    command: "bash -c 'if [ ! -f /tmp/update_run.sh ]; then echo \"ERROR: Did you forget the update_run.sh file that came with this docker-compose.yml file?\" && exit 1 ; else /tmp/update_run.sh && /etc/confluent/docker/run ; fi'"

  schemaregistry0:
    image: confluentinc/cp-schema-registry:7.2.1
    ports:
      - 8085:8085
    depends_on:
      - kafka0
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka0:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry0
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry0:8085

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas

  #  schemaregistry1:
  #    image: confluentinc/cp-schema-registry:7.2.1
  #    ports:
  #      - 18085:8085
  #    depends_on:
  #      - kafka1
  #    environment:
  #      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:29092
  #      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
  #      SCHEMA_REGISTRY_HOST_NAME: schemaregistry1
  #      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry1:8085
  #
  #      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
  #      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
  #      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas

  kafka-connect0:
    image: confluentinc/cp-kafka-connect:7.2.1
    ports:
      - 8083:8083
    depends_on:
      - kafka0
      - schemaregistry0
    #      - busybox
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka0:29092
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: _connect_configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: _connect_offset
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: _connect_status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect0
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/usr/share/java/kafka-connect-redis,/usr/share/java/kafka"

  #  kafka-init-topics:
  #    image: confluentinc/cp-kafka:7.2.1
  #    volumes:
  #      - ./data/message.json:/data/message.json
  #    depends_on:
  #      - kafka1
  #    command: "bash -c 'echo Waiting for Kafka to be ready... && \
  #               cub kafka-ready -b kafka1:29092 1 30 && \
  #               kafka-topics --create --topic second.users --partitions 3 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
  #               kafka-topics --create --topic second.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
  #               kafka-topics --create --topic first.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka0:29092 && \
  #               kafka-console-producer --bootstrap-server kafka1:29092 -topic second.users < /data/message.json'"

  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    environment:
      - REDIS_USERNAME=username
      - REDIS_PASSWORD=password
      - REDIS_DATABASE=0
    volumes:
      - redis-data:/data

  postgres:
    image: postgres:latest
    container_name: postgres-db
    environment:
      POSTGRES_USER: username
      POSTGRES_PASSWORD: password
      POSTGRES_DB: common-db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - postgres-network

  elasticsearch:
    image: elasticsearch:8.15.2
    environment:
      - discovery.type=single-node
      - ELASTIC_PASSWORD=password
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - zipkin-network

  logstash:
    image: logstash:8.15.2
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    #    volumes:
    #      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
    networks:
      - zipkin-network

  kibana:
    image: kibana:8.15.2
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTIC_USERNAME=elastic
      - ELASTIC_PASSWORD=password
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - zipkin-network

  zipkin:
    image: openzipkin/zipkin:latest
    container_name: zipkin
    ports:
      - "9411:9411"
    depends_on:
      - elasticsearch
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HTTP_PORT=9200
      - ES_HOSTS=http://elasticsearch:9200
      - ZIPKIN_UI_ENVIRONMENT=production
    networks:
      - zipkin-network

  camunda:
    image: camunda/camunda-bpm-platform:latest
    container_name: camunda
    ports:
      - "8088:8080"
    environment:
      - DB_DRIVER=org.postgresql.Driver
      - DB_URL=jdbc:postgresql://db:5432/camunda
      - DB_USERNAME=camunda
      - DB_PASSWORD=camunda
      - WAIT_FOR=db:5432
      - CAMUNDA_ADMIN_USER=admin
      - CAMUNDA_ADMIN_PASSWORD=admin
    depends_on:
      - db

  db:
    image: postgres:13
    container_name: camunda-db
    environment:
      POSTGRES_USER: camunda
      POSTGRES_PASSWORD: camunda
      POSTGRES_DB: camunda
    ports:
      - "5432:5432"
    volumes:
      - camunda-db-data:/var/lib/postgresql/data


volumes:
  kafka-data:
  redis-data:
  common-function-data:
  kafka-connect-redis:
  zipkin:
  connectors:
  postgres_data:
    driver: local
  esdata:
  camunda-db-data:

networks:
  postgres-network:
    driver: bridge
  zipkin-network:
    driver: bridge